{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STSN for Complex-valued Data & Real-valued Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelim. Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emanuelazcona/py3env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\t\t\t\t# clears Tensorflow CPU for my mac Unix terminal\n",
    "os.system('cls' if os.name == 'nt' else 'clear')\t# clears the terminal window screen (clc equiv. to MATLAB)\n",
    "\n",
    "import pickle\n",
    "\n",
    "from weightGen import *\n",
    "from layers import transmitComplex\n",
    "from costMask import costMask\n",
    "\n",
    "np.random.seed(7)\t\t# seeding the random number generator to reproduce identical results\n",
    "tf.set_random_seed(7)\t# seed Tensorflow random numebr generator as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scatter-points: 01\n",
      "Time units: 10\n"
     ]
    }
   ],
   "source": [
    "userScatter = str( input(\"Scatter-points: \") )\n",
    "userTime = str( input(\"Time units: \") )\n",
    "\n",
    "layers = int(userTime)\t# number of scatter/prop. layers to navigate through\n",
    "expectedScatter = int(userScatter)\n",
    "\n",
    "if len( userScatter ) is 1:\n",
    "\tuserScatter = \"0\" + userScatter\n",
    "if len( userTime ) is 1:\n",
    "\tuserTime = \"0\" + userTime\n",
    "\n",
    "fileName = 'non_zero_data/scatter' + userScatter + '_T' + userTime + '_all_'\n",
    "X = np.transpose( np.genfromtxt(fileName + 'in.csv', delimiter = ',') )\n",
    "Y = np.transpose( np.genfromtxt(fileName + 'out.csv', delimiter = ',') )\n",
    "\n",
    "# X = np.ones((15,30)) # FOR TESTING\n",
    "# Y = np.random.random((15,30)) # FOR TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print User Input Info. & Extract Number of Samples/Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model contains:\n",
      "\t- 10 time units\n",
      "\t- 01 expected scatter points\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print Information\n",
    "print(\"This model contains:\")\n",
    "print(\"\\t- \" + userTime + \" time units\")\n",
    "print(\"\\t- \" + userScatter + \" expected scatter points\\n\")\n",
    "\n",
    "sampN, featN = X.shape\t# sampN: number of training samples, featN: features per sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Weight Generation For Material"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Weight Index of Mask: 50\n",
      "Ending Weight Index of Mask: 70\n",
      "\t- 100 total weights\n",
      "\t- 21 trainable weights out of total weights (masked region)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wN = featN//4\t# number of transmission weights\n",
    "start = int(input(\"Starting Weight Index of Mask: \"))\t# starting index (1 <--> wN)\n",
    "end = int(input(\"Ending Weight Index of Mask: \"))\t\t# ending index (start <--> wN)\n",
    "\n",
    "print(\"\\t- \" + str(wN) + \" total weights\")\n",
    "print(\"\\t- \" + str(end-start+1) + \" trainable weights out of total weights (masked region)\\n\")\n",
    "\n",
    "# extract arrays for trainable & frozen weights\n",
    "W_left, W_train, W_right = weightCreation(start, end, wN)\n",
    "W_tens = weightConcat(W_left, W_train, W_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Untrainable Variable Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tens = tf.placeholder(dtype = tf.float64, shape = [sampN,featN])\n",
    "Y_tens = tf.placeholder(dtype = tf.float64, shape = [sampN,featN])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat_tens = transmitComplex(X_tens, W_tens, layers)\t\t# prediction function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Zero-Mask to Output of Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat_masked = costMask(Yhat_tens - Y_tens, start, end)\t# masking region \"we don't know\" for the cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares Cost on Unmasked Region(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "least_squares = tf.norm(Yhat_masked, ord=2)**2 / (featN - ((end*4) - (start*4-3) + 1))\t#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Optimizer ... ... ...\n",
      "Specify learning-rate of the model (3-decimal precision): 0.08\n",
      "Done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Building Optimizer ... ... ...\")\n",
    "lr = float(input(\"Specify learning-rate of the model (3-decimal precision): \"))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(least_squares, var_list = [W_train])\n",
    "print(\"Done!\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor X:\n",
      "[[ 0.1353  -0.06765  0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " ...\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]]\n",
      "\n",
      "Tensor W: \n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      "  1. 1. 1. 1.]]\n",
      "\n",
      "Trainable part of W (weights 50 through 70):\n",
      "[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      "Tensor Y: \n",
      "[[ 0.      -0.06765  0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " ...\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]\n",
      " [ 0.      -0.       0.      ... -0.       0.      -0.     ]]\n",
      "\n",
      "--------- Starting Training ---------\n",
      "\n",
      "Epoch: 1\t\tLoss: 1.0466821473892503\n",
      "[[0.92000069 0.9200002  0.92000017 0.9200004  0.92000346 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 2\t\tLoss: 1.0330034487011477\n",
      "[[0.95528232 0.86334036 0.8478629  0.84810861 0.85163093 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 3\t\tLoss: 1.025577834552473\n",
      "[[1.00930502 0.83071955 0.78307758 0.78374526 0.7936641  1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 4\t\tLoss: 1.0208903204321884\n",
      "[[1.06728854 0.81987625 0.72652717 0.72705235 0.74512512 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 5\t\tLoss: 1.0193497455910634\n",
      "[[1.11737833 0.82481857 0.68003068 0.67859774 0.7052497  1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 6\t\tLoss: 1.0208514076689528\n",
      "[[1.14589588 0.83833497 0.64592412 0.63921211 0.67340898 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 7\t\tLoss: 1.023526524261633\n",
      "[[1.14823483 0.85395334 0.62546312 0.60935474 0.64886006 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 8\t\tLoss: 1.0247039029069926\n",
      "[[1.13036452 0.86766305 0.61753698 0.58855069 0.63065051 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 9\t\tLoss: 1.02364145960736\n",
      "[[1.09954651 0.87871297 0.61937833 0.57550406 0.61773741 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 10\t\tLoss: 1.0213435834560256\n",
      "[[1.06169907 0.88867027 0.62779993 0.56852571 0.60911802 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 11\t\tLoss: 1.0192227121543598\n",
      "[[1.02219657 0.8998253  0.63988258 0.5659075  0.60391037 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 12\t\tLoss: 1.0181849342226825\n",
      "[[0.98645117 0.9139957  0.65323243 0.56615815 0.60139835 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 13\t\tLoss: 1.0182932904665734\n",
      "[[0.95928421 0.93197998 0.66604315 0.56813128 0.60106056 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 14\t\tLoss: 1.018941010799582\n",
      "[[0.94347291 0.95352652 0.67704342 0.57108148 0.60259166 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 15\t\tLoss: 1.0194047805973305\n",
      "[[0.93906218 0.97751174 0.6853712  0.57467278 0.6059153  1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n",
      "Epoch: 16\t\tLoss: 1.0193716147344942\n",
      "[[0.94400592 1.00208203 0.69044356 0.57896424 0.61118592 1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.         1.         1.         1.\n",
      "  1.         1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 2000\n",
    "loss_tolerance = 1e-8\n",
    "\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))) as sess:\n",
    "# with tf.Session() as sess:\n",
    "\tsess.run( tf.global_variables_initializer() )\n",
    "\t\n",
    "\tprint(\"Tensor X:\")\t\t# show info. for X\n",
    "\tprint(X)\n",
    "\tprint(\"\")\n",
    "\n",
    "\tprint(\"Tensor W: \") \t# show info. for W total\n",
    "\tprint(W_tens.eval())\n",
    "\tprint(\"\")\n",
    "\n",
    "\t# show only the trainable part of W\n",
    "\tprint(\"Trainable part of W (weights \" + str(start) + \" through \" + str(end) + \"):\")\n",
    "\tprint(W_train.eval())\n",
    "\tprint(\"\")\n",
    "\n",
    "\tprint(\"Tensor Y: \")\t\t# show info. for Y\n",
    "\tprint(Y)\n",
    "\tprint(\"\")\n",
    "\n",
    "\tprint(\"--------- Starting Training ---------\\n\")\n",
    "\tfor i in range(1, epochs+1):\n",
    "\n",
    "\t\t# run X and Y dynamically into the network per iteration\n",
    "\t\t_, loss_value = sess.run([train_op, least_squares], feed_dict = {X_tens: X, Y_tens: Y})\n",
    "\t\t\n",
    "\t\tW_tens = tf.clip_by_value(W_tens, 0.0, 1.0)\t# after updating the weights clip them to stay between 0 and 1\n",
    "\t\tcurrStatus = [loss_value]\t# status of the network for the current epoch\n",
    "\n",
    "\t\t# add the weights to the status of the network for current epoch\n",
    "\t\tfor w in W_tens.eval()[0]:\n",
    "\t\t\tcurrStatus.append(w)\n",
    "\n",
    "\t\t# saves objects for every iteration\n",
    "\t\tfileFolder = \"results/non_zero/n\" + userScatter + \"_T\" + userTime + \"_Mask_\" + str(start) + \"_\" + str(end) + \"_lr{0:.3f}\".format(lr)\n",
    "\n",
    "\t\tif not os.path.exists(fileFolder):\n",
    "\t\t\tos.makedirs(fileFolder)\n",
    "\t\tfileName = \"/epoch\" + str(i) + \"_lossAndWeights.p\"\n",
    "\t\tpickle.dump( currStatus, open( fileFolder + fileName, \"wb\" ) )\n",
    "\n",
    "\t\t# print information for the user about loss and weights\n",
    "\t\tprint(\"Epoch: \" + str(i) + \"\\t\\tLoss: \" + str(loss_value))\n",
    "\t\tprint(W_train.eval())\n",
    "\n",
    "\t\tif loss_value <= loss_tolerance:\n",
    "\t\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
